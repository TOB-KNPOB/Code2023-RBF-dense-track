{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fig = True\n",
    "export_folder = '../output/graph'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load benchmark results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fps_ls = (10, 60, 120)\n",
    "approach_ls = ('Ours', 'ECPD', 'CPD', 'BCPD')\n",
    "app2code = {\n",
    "    'Ours': 'rbf',\n",
    "    'ECPD': 'ecpd',\n",
    "    'CPD': 'cpd',\n",
    "    'BCPD': 'bcpd',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from mesh4d import utils\n",
    "from benchmark import Bemchmarker_marker_guided, Bemchmarker_marker_less\n",
    "\n",
    "benchmarker_dict = {}\n",
    "\n",
    "for fps in fps_ls:\n",
    "    benchmarker_dict[fps] = {}\n",
    "\n",
    "    for approach in approach_ls:\n",
    "        path = os.path.join('../output/', f'{fps}fps', app2code[approach], 'benchmark.pkl')\n",
    "        benchmarker = utils.load_pkl_object(path)\n",
    "        benchmarker_dict[fps][approach] = benchmarker\n",
    "    \n",
    "benchmarker_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_duration(benchmarker = None):\n",
    "    if benchmarker is None:\n",
    "        return 'time (s)'\n",
    "\n",
    "    else:\n",
    "        return benchmarker.duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_acc_control(benchmarker = None):\n",
    "    if benchmarker is None:\n",
    "        return 'acc-c (cm)'\n",
    "\n",
    "    else:\n",
    "        if type(benchmarker) == Bemchmarker_marker_less:\n",
    "            return np.nan\n",
    "        \n",
    "        else:\n",
    "            return benchmarker.diff_control['dist_mean'] / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc_noncontrol(benchmarker = None):\n",
    "    if benchmarker is None:\n",
    "        return 'acc-nc (cm)'\n",
    "\n",
    "    else:\n",
    "        if type(benchmarker) == Bemchmarker_marker_less:\n",
    "            return benchmarker.diff_noncontrol['dist_mean']\n",
    "        \n",
    "        else:\n",
    "            dist_ls = [diff['dist_mean'] for diff in benchmarker.diff_noncontrol.values()]\n",
    "            return np.mean(dist_ls) / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# init data frame\n",
    "df = pd.DataFrame(columns=('Dataset', 'Metric') + approach_ls)\n",
    "\n",
    "# fill in data\n",
    "row = 0\n",
    "get_metric_ls = [get_duration, get_acc_control, get_acc_noncontrol]\n",
    "\n",
    "for fps in fps_ls:\n",
    "    for get_metric in get_metric_ls:\n",
    "        row_data = [f'DBL-{fps}', get_metric()]\n",
    "\n",
    "        for approach in approach_ls:\n",
    "            matric = get_metric(benchmarker_dict[fps][approach])\n",
    "            row_data.append(matric)\n",
    "        \n",
    "        df.loc[row] = row_data\n",
    "        row = row + 1\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_styler = df.set_index(['Dataset', 'Metric']).style\n",
    "df_styler.format(\n",
    "    precision=2, \n",
    "    na_rep='--',\n",
    "    )\n",
    "df_styler.highlight_min(\n",
    "    axis=1, \n",
    "    props='bfseries: ;'\n",
    "    )\n",
    "df_styler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_styler.to_latex(\n",
    "    position='h',\n",
    "    position_float='centering',\n",
    "    hrules=True,\n",
    "    # label='',\n",
    "    # caption='',\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.dpi'] = 600\n",
    "\n",
    "app2col = {\n",
    "    'Ours': 'goldenrod',\n",
    "    'ECPD': 'teal',\n",
    "    'CPD': 'olive',\n",
    "    'BCPD': 'hotpink',\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computation time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time = df[df['Metric']=='time (s)'].set_index('Dataset')\n",
    "df_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for approach in df_time.columns[1:]:\n",
    "    plt.plot(df_time[approach], label=approach, marker='.', color=app2col[approach])\n",
    "\n",
    "plt.ylabel('Computation Time (s)')\n",
    "plt.legend()\n",
    "\n",
    "if save_fig:\n",
    "    plt.savefig(os.path.join(export_folder, f'compute_time.png'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alignment on control landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dist_control(benchmarker):\n",
    "    dist_ls = []\n",
    "\n",
    "    for marker in benchmarker.diff_control['diff_dict'].values():\n",
    "        dist_ls.append(marker['dist'])\n",
    "\n",
    "    return np.array(dist_ls)/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []\n",
    "colors = []\n",
    "\n",
    "approach_ls_here = ('Ours', 'ECPD')\n",
    "\n",
    "for approach in approach_ls_here:\n",
    "    for fps in fps_ls:\n",
    "        labels.append(f'DBL-{fps}')\n",
    "        colors.append(app2col[approach])\n",
    "        data.append(get_dist_control(benchmarker_dict[fps][approach]).reshape((-1,)))\n",
    "\n",
    "bplot = plt.boxplot(\n",
    "    x = data, labels = labels,\n",
    "    patch_artist=True, showmeans=True, meanline=True, sym='',\n",
    "    medianprops=dict(color='black'), meanprops=dict(color='black'),\n",
    "    )\n",
    "\n",
    "for patch, color in zip(bplot['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "\n",
    "plt.ylabel('Alignment Error (cm)')\n",
    "plt.legend(\n",
    "    bplot['boxes'][0::len(fps_ls)], \n",
    "    approach_ls_here\n",
    "    )\n",
    "\n",
    "if save_fig:\n",
    "    plt.savefig(os.path.join(export_folder, f'align_control.png'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "\n",
    "for fps in fps_ls:\n",
    "    num = num + 1\n",
    "    ax = plt.subplot(310 + num)\n",
    "\n",
    "    for approach in approach_ls_here:\n",
    "        dist = get_dist_control(benchmarker_dict[fps][approach]).mean(axis=0)\n",
    "        plt.plot(\n",
    "            np.linspace(0, 1, len(dist)), dist,\n",
    "            label=approach, color=app2col[approach],\n",
    "            )\n",
    "    \n",
    "    plt.legend(fontsize=7)\n",
    "\n",
    "    if num == round(len(fps_ls)/2):\n",
    "        plt.ylabel('Alignment Error (cm)')\n",
    "\n",
    "    if num < len(fps_ls):\n",
    "        plt.tick_params('x', labelbottom=False)\n",
    "    else:\n",
    "        plt.xlabel('Time (s)')\n",
    "\n",
    "if save_fig:\n",
    "    plt.savefig(os.path.join(export_folder, f'align_control_time.png'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alignment on non-control landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dist_noncontrol(benchmarker):\n",
    "    dist_ls = []\n",
    "\n",
    "    if type(benchmarker) == Bemchmarker_marker_less:\n",
    "        for marker in benchmarker.diff_noncontrol['diff_dict'].values():\n",
    "            dist_ls.append(marker['dist'])\n",
    "\n",
    "    elif type(benchmarker) == Bemchmarker_marker_guided:\n",
    "        for name, marker in benchmarker.diff_noncontrol.items():   \n",
    "            dist_ls.append(marker['diff_dict'][name]['dist'])\n",
    "\n",
    "    return np.array(dist_ls)/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []\n",
    "colors = []\n",
    "\n",
    "for approach in approach_ls:\n",
    "    for fps in fps_ls:\n",
    "        labels.append(f'DBL-{fps}')\n",
    "        colors.append(app2col[approach])\n",
    "        data.append(get_dist_noncontrol(benchmarker_dict[fps][approach]).reshape((-1,)))\n",
    "\n",
    "bplot = plt.boxplot(\n",
    "    x = data, labels = labels,\n",
    "    patch_artist=True, showmeans=True, meanline=True, sym='',\n",
    "    medianprops=dict(color='black'), meanprops=dict(color='black'),\n",
    "    )\n",
    "\n",
    "for patch, color in zip(bplot['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "\n",
    "plt.gca().set_aspect(1/3)\n",
    "plt.xticks(fontsize=7)\n",
    "plt.ylabel('Alignment Error (cm)')\n",
    "plt.legend(\n",
    "    bplot['boxes'][0::len(fps_ls)], \n",
    "    approach_ls\n",
    "    )\n",
    "\n",
    "if save_fig:\n",
    "    plt.savefig(os.path.join(export_folder, f'align_noncontrol.png'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "\n",
    "for fps in fps_ls:\n",
    "    num = num + 1\n",
    "    ax = plt.subplot(310 + num)\n",
    "\n",
    "    for approach in approach_ls:\n",
    "        dist = get_dist_noncontrol(benchmarker_dict[fps][approach]).mean(axis=0)\n",
    "        plt.plot(\n",
    "            np.linspace(0, 1, len(dist)), dist,\n",
    "            label=approach, color=app2col[approach],\n",
    "            )\n",
    "    \n",
    "    plt.legend(fontsize=7)\n",
    "    plt.title(f'DBL-{fps}', fontsize=7)\n",
    "\n",
    "    if num == round(len(fps_ls)/2):\n",
    "        plt.ylabel('Alignment Error (cm)')\n",
    "\n",
    "    if num < len(fps_ls):\n",
    "        plt.tick_params('x', labelbottom=False)\n",
    "    else:\n",
    "        plt.xlabel('Time (s)')\n",
    "\n",
    "if save_fig:\n",
    "    plt.savefig(os.path.join(export_folder, f'align_noncontrol_time.png'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mesh4d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
